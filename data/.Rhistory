gd<-grad.descent(huber.loss,x0=beta,max.iter=200,step.size = 0.001,stopping.deriv = 0.1)
gd$k
gd$x
#it takes 127 to converge.
gdx<-gd$x
obj<-apply(gd$xmat[,1:gd$k],2,huber.loss)
plot(1:gd$k,obj[1:gd$k],xlab="iteration",ylab="x value",type="l")
#when iteration increases, the value decreases.
gd6<-grad.descent(huber.loss,x0=beta,max.iter=200,step.size = 0.1,stopping.deriv = 0.1)
gd6$k
obj6<-rep(NA,gd6$k)
for (i in 1:gd6$k){
obj6[i]<-huber.loss(gd6$xmat[,i])
}
plot((gd6$k-50):gd6$k,obj6[(gd6$k-50):gd6$k],type="l")
#it shows the the value oscilated, when means the step size is too big.
gd$x
lm.coefs
sparse.grad.descent <- function(f, x0, max.iter = 200, step.size = 0.001, stopping.deriv = 0.1,...){
n <- length(x0)
xmat <- matrix(0, nrow = n, ncol = max.iter)
xmat[,1] <- x0
for (k in 2:max.iter) {
# Calculate the gradient
grad.cur <- grad(f, xmat[ ,k-1], ...)
# Should we stop?
if (all(abs(grad.cur) < stopping.deriv)) {
k <- k-1; break
}
xmat1 <- xmat[,k-1] - step.size %*% grad.cur
xmat1[which(abs(xmat1) <= 0.05)] <- 0
xmat[,k]<-xmat1
}
xmat <- xmat[ ,1:k] # Trim
return(list(x = xmat[,k], xmat = xmat, k = k))
}
gd.sparse <- sparse.grad.descent(huber.loss, x0 = rep(0, p), max.iter = 200)
gd.sparse$k
gd.sparse$x
lm<-lm(y~x+0)
beta_lm <- lm$coefficients
MSE<-function(beta){
return((sum((beta-b)^2))/90)
}
MSE_lm<-MSE(beta_lm)
MSE_grad <- MSE(gd$x)
MSE_coef <- MSE(gd.sparse$x)
set.seed(10)
x <- matrix(rnorm(n*p), n, p)
y <- x %*% b+ rt(n, df=2)
lm.coefs <- coef(lm(y ~ x + 0))
gd9<-grad.descent(huber.loss,x0=beta,max.iter=200,step.size = 0.001,stopping.deriv = 0.1)
sgd9<-sparse.grad.descent(huber.loss, x0 = rep(0, p), max.iter = 200)
sgd9$x
gd9$x
MSE_gd9<-MSE(gd9$x)
MSE_gd9
MSE_sgd9<-MSE(sgd9$x)
MSE_sgd9
set.seed(10)
MSE_gd10<-rep(0,10)
MSE_sgd10<-rep(0,10)
for (i in 1:10){
x <- matrix(rnorm(n*p), n, p)
y<- x %*% b+ rt(n, df=2)
gd10<-grad.descent(huber.loss,x0=beta,max.iter=200,step.size = 0.001,stopping.deriv = 0.1)
sgd10<-sparse.grad.descent(huber.loss, x0 = rep(0, p), max.iter = 200)
MSE_gd10[i]<-MSE(gd10$x)
MSE_sgd10[i]<-MSE(sgd10$x)
}
MSE_gd10
MSE_sgd10
c(mean(MSE_gd10),min(MSE_gd10))
c(mean(MSE_sgd10),min(MSE_sgd10))
knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(tidytext)
libinsrary(tidyverse)
install.packages("tidyverse")
library(tm)
library(tidytext)
library(tidyverse)
library(DT)
urlfile<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/cleaned_hm.csv'
hm_data <- read_csv(urlfile)
corpus <- VCorpus(VectorSource(hm_data$cleaned_hm))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, character(0))%>%
tm_map(stripWhitespace)
stemmed <- tm_map(corpus, stemDocument) %>%
tidy() %>%
select(text)
dict <- tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
data("stop_words")
word <- c("happy","ago","yesterday","lot","today","months","month",
"happier","happiest","last","week","past")
stop_words <- stop_words %>%
bind_rows(mutate(tibble(word), lexicon = "updated"))
completed <- stemmed %>%
mutate(id = row_number()) %>%
unnest_tokens(stems, text) %>%
bind_cols(dict) %>%
anti_join(stop_words, by = c("dictionary" = "word"))
completed <- completed %>%
group_by(stems) %>%
count(dictionary) %>%
mutate(word = dictionary[which.max(n)]) %>%
ungroup() %>%
select(stems, word) %>%
distinct() %>%
right_join(completed) %>%
select(-stems)
completed <- completed %>%
group_by(id) %>%
summarise(text = str_c(word, collapse = " ")) %>%
ungroup()
install.packages(â€˜stringrâ€?
install.packages("stringr")
install.packages("stringr")
knitr::opts_chunk$set(echo = TRUE)
completed <- completed %>%
group_by(id) %>%
summarise(text = str_c(word, collapse = " ")) %>%
ungroup()
knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(tidytext)
library(tidyverse)
library(DT)
library(tm)
library(tidytext)
library(tidyverse)
library(DT)
library(stringr)
urlfile<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/cleaned_hm.csv'
hm_data <- read_csv(urlfile)
corpus <- VCorpus(VectorSource(hm_data$cleaned_hm))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, character(0))%>%
tm_map(stripWhitespace)
stemmed <- tm_map(corpus, stemDocument) %>%
tidy() %>%
select(text)
dict <- tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
data("stop_words")
word <- c("happy","ago","yesterday","lot","today","months","month",
"happier","happiest","last","week","past")
stop_words <- stop_words %>%
bind_rows(mutate(tibble(word), lexicon = "updated"))
completed <- stemmed %>%
mutate(id = row_number()) %>%
unnest_tokens(stems, text) %>%
bind_cols(dict) %>%
anti_join(stop_words, by = c("dictionary" = "word"))
completed <- completed %>%
group_by(stems) %>%
count(dictionary) %>%
mutate(word = dictionary[which.max(n)]) %>%
ungroup() %>%
select(stems, word) %>%
distinct() %>%
right_join(completed) %>%
select(-stems)
completed <- completed %>%
group_by(id) %>%
summarise(text = str_c(word, collapse = " ")) %>%
ungroup()
hm_data <- hm_data %>%
mutate(id = row_number()) %>%
inner_join(completed)
datatable(hm_data)
write_csv(hm_data, "../output/processed_moments.csv")
write_csv(hm_data, "../output/processed_moments.csv")
library(tidyverse)
library(tidytext)
library(DT)
library(scales)
library(wordcloud2)
install.packages("wordcloud2")
install.packages("gridExtra")
install.packages("ngram")
install.packages("shiny")
install.packages("shiny")
install.packages("igraph")
install.packages("ggraph")
library(tidyverse)
library(tidytext)
library(DT)
library(scales)
library(wordcloud2)
library(gridExtra)
library(ngram)
library(shiny)
library(igraph)
library(ggraph)
hm_data <- read_csv("../output/processed_moments.csv")
urlfile<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/demographic.csv'
demo_data <- read_csv(urlfile)
hm_data <- hm_data %>%
inner_join(demo_data, by = "wid") %>%
select(wid,
original_hm,
gender,
marital,
parenthood,
reflection_period,
age,
country,
ground_truth_category,
text) %>%
mutate(count = sapply(hm_data$text, wordcount)) %>%
filter(gender %in% c("m", "f")) %>%
filter(marital %in% c("single", "married")) %>%
filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m")) %>%
mutate(reflection_period = fct_recode(reflection_period,
months_3 = "3m", hours_24 = "24h"))
library(tidyverse)
library(tidytext)
library(DT)
library(scales)
library(wordcloud2)
library(gridExtra)
library(ngram)
library(shiny)
library(igraph)
library(ggraph)
hm_data <- read_csv("../output/processed_moments.csv")
urlfile<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/demographic.csv'
demo_data <- read_csv(urlfile)
hm_data <- hm_data %>%
inner_join(demo_data, by = "wid") %>%
select(wid,
original_hm,
gender,
marital,
parenthood,
reflection_period,
age,
country,
ground_truth_category,
text) %>%
mutate(count = sapply(hm_data$text, wordcount)) %>%
filter(gender %in% c("m", "f")) %>%
filter(marital %in% c("single", "married")) %>%
filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m")) %>%
mutate(reflection_period = fct_recode(reflection_period,
months_3 = "3m", hours_24 = "24h"))
hm_data <- hm_data %>%
inner_join(demo_data, by = "wid") %>%
select(wid,
original_hm,
gender,
marital,
parenthood,
reflection_period,
age,
country,
ground_truth_category,
text) %>%
mutate(count = sapply(hm_data$text, wordcount)) %>%
filter(gender %in% c("m", "f")) %>%
filter(marital %in% c("single", "married")) %>%
filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m")) %>%
hm_data <- hm_data %>%
inner_join(demo_data, by = "wid") %>%
select(wid,
original_hm,
gender,
marital,
parenthood,
reflection_period,
age,
country,
ground_truth_category,
text) %>%
mutate(count = sapply(hm_data$text, wordcount)) %>%
filter(gender %in% c("m", "f")) %>%
filter(marital %in% c("single", "married")) %>%
filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m"))
datatable(hm_data)
library(tidyverse)
library(tidytext)
library(DT)
library(scales)
library(wordcloud2)
library(gridExtra)
library(ngram)
library(shiny)
library(igraph)
library(ggraph)
hm_data <- read_csv("../output/processed_moments.csv")
urlfile<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/demographic.csv'
demo_data <- read_csv(urlfile)
hm_data <- hm_data %>%
inner_join(demo_data, by = "wid") %>%
select(wid,
original_hm,
gender,
marital,
parenthood,
reflection_period,
age,
country,
ground_truth_category,
text) %>%
mutate(count = sapply(hm_data$text, wordcount)) %>%
filter(gender %in% c("m", "f")) %>%
filter(marital %in% c("single", "married")) %>%
filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m"))
datatable(hm_data)
write_csv(hm_data, "../output/processed_moments.csv")
datatable(hm_data)
write_csv(hm_data, "C:\\Users\\Andrew\\Documents\\GitHub\\Fall2018-Proj1-andrewzhouxlxl\\output\\processed_moments2.csv")
load("C:/Users/Andrew/Downloads/Spr2017-proj2-grp14-master/app/server.R")
install.packages("shiny")
shiny::runApp('C:/Users/Andrew/Downloads/Spr2017-proj2-grp14-master/app')
install.packages("leaflet")
install.packages("shinydashboard")
install.packages("XML")
install.packages("leaflet")
install.packages("shinythemes")
runApp('C:/Users/Andrew/Downloads/Spr2017-proj2-grp14-master/app')
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("shinyjs")
shiny::runApp('C:/Users/Andrew/Downloads/Fall2017-project2-grp5-master/app')
runApp('C:/Users/Andrew/Downloads/Spr2017-proj2-grp14-master/app')
runApp('C:/Users/Andrew/Downloads/Fall2017-project2-grp5-master/app')
runApp('C:/Users/Andrew/Downloads/Spr2017-proj2-grp14-master/app')
install.packages('rsconnect')
install.packages("rsconnect")
rsconnect::setAccountInfo(name='lingchao',
token='8DA9AC9A34E7F53D5642ADB0B6A15FDA',
secret='<SECRET>')
rsconnect::setAccountInfo(name='lingchao',
token='8DA9AC9A34E7F53D5642ADB0B6A15FDA',
secret='<SECRET>')
rsconnect::setAccountInfo(name='lingchao',
token='8DA9AC9A34E7F53D5642ADB0B6A15FDA',
secret='/P0H52E7lmb1mFnwYE0qJ1IXtjGSSBC1YFrsGj2v')
shiny::runApp('C:/Users/Andrew/Downloads/Spr2017-proj2-grp14-master/app')
runApp('C:/Users/Andrew/Downloads/Fall2017-project2-grp5-master/app')
runApp('C:/Users/Andrew/Downloads/Shiny-Dashboard-Template-master')
runApp('D:/project')
install.packages('leaflet.extras')
runApp('D:/project')
install.packages('shinyWidgets')
install.packages('maps')
install.packages("maps")
install.packages("rgdal")
install.packages("devtools")
install.packages("devtools")
install.packages("tigris")
install.packages("sp")
install.packages("data.table")
install.packages("maptools")
install.packages("maptools")
install.packages("httr")
install.packages("httr")
shiny::runApp('D:/project')
runApp('D:/project')
runApp('C:/Users/Andrew/Downloads/Fall2017-project2-grp5-master/app')
runApp('C:/Users/Andrew/Downloads/Fall2017-project2-grp5-master/app')
runApp('C:/Users/Andrew/Downloads/Fall2017-project2-grp5-master/app')
library(shinydashboard)
library(googleway)
install.packages('googleway')
install.packages('ggmap')
ggmap
res <- google_directions(
key = api_key
, origin = x[['origin']]
, destination = x[['destination']]
)
df_result <- data.frame(
origin = x[['origin']]
, destination = x[['destination']]
, route = res$routes$overview_polyline$points
)
return(df_result)
lst_directions <- apply(df_locations, 1, function(x){
res <- google_directions(
key = api_key
, origin = x[['origin']]
, destination = x[['destination']]
)
df_result <- data.frame(
origin = x[['origin']]
, destination = x[['destination']]
, route = res$routes$overview_polyline$points
)
return(df_result)
})
df_directions <- do.call(rbind, lst_directions)
google_map(key = map_key ) %>%
add_polylines(data = df_directions, polyline = "route")
source('C:/Users/Andrew/Downloads/Fall2018-Project2-sec1proj2_grp5-master/app/google-map.R')
library(shiny)
library(shinydashboard)
library(googleway)
library(ggmap)
devtools::install_github("dkahle/ggmap")
register_google(key = 'AIzaSyARO9UpPhYPi5HAXWngJ3C4z2zTmdT09mc')
ui <- dashboardPage(
dashboardHeader(),
dashboardSidebar(),
dashboardBody(
textInput(inputId = "origin", label = "Origin"),
textInput(inputId = "destination", label = "Destination"),
actionButton(inputId = "getRoute", label = "Get Rotue"),
google_mapOutput("myMap")
)
)
install.packages(c("backports", "BH", "caTools", "cli", "evaluate", "fansi", "ggforce", "ggraph", "ggrepel", "gridExtra", "highr", "hms", "htmlwidgets", "igraph", "irlba", "ISLR", "knitr", "lazyeval", "mime", "ngram", "packrat", "R6", "Rcpp", "RCurl", "readxl", "reshape2", "rmarkdown", "rprojroot", "rstudioapi", "sourcetools", "stringi", "stringr", "tidyverse", "tweenr", "wordcloud2", "xtable", "yaml"))
q()
shiny::runApp('C:/Users/Andrew/Downloads/Fall2017-project2-grp5-master/app')
shiny::runApp()
runApp()
runApp('~/GitHub/Fall2018-Project2-sec1_proj2_gr5/app')
runApp('~/GitHub/Fall2018-Project2-sec1_proj2_gr5/app')
runApp('~/GitHub/Fall2018-Project2-sec1_proj2_gr5/app')
runApp('~/GitHub/Fall2018-Project2-sec1_proj2_gr5/app')
load("C:/Users/cjsly/Documents/GitHub/Fall2017-project2-grp6/output/housing.RData")
View(housing)
housing<- read.csv("../data/housing.csv",header=TRUE, stringsAsFactors =FALSE)
packages.used=c("leaflet","geosphere","shiny","dplyr","shinyjs")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
library(dplyr)
library(leaflet)
library(shiny)
library(shinyjs)
museum<-na.omit(read.csv("../data/museums.csv"))
theatre<-read.csv("../data/theatre.csv")
gallery<-read.csv("../data/Gallery.csv")
library<-read.csv("../data/library.csv")
restaurant<- read.csv("../data/restaurant_new.csv")
icon_museum<-icons(iconUrl = 'icon_museum.png',iconHeight = 15, iconWidth = 15)
icon_theatre<-icons(iconUrl = 'icon_theatre.png', iconHeight = 18, iconWidth = 18)
icon_library<-icons(iconUrl = 'icon_library.png', iconHeight = 18, iconWidth = 18)
icon_gallery<-icons(iconUrl = 'icon_gallery.png', iconHeight = 18, iconWidth = 18)
icon_rest<-icons(iconUrl =  'icon_rest.png', iconHeight=25, iconWidth = 25)
housing<- read.csv("../data/housing.csv",header=TRUE, stringsAsFactors =FALSE)
runApp('~/GitHub/Fall2018-Project2-sec1_proj2_gr5/app')
housing<- read.csv("../data/housing.csv",header=TRUE, stringsAsFactors =FALSE)
setwd("~/GitHub/Fall2018-Project2-sec1_proj2_gr5")
housing<- read.csv("../data/housing.csv",header=TRUE, stringsAsFactors =FALSE)
setwd("~/GitHub/Fall2018-Project2-sec1_proj2_gr5")
housing<- read.csv("../data/housing.csv",header=TRUE, stringsAsFactors =FALSE)
read.csv("../data/housing.csv",header=TRUE, stringsAsFactors =FALSE)
setwd("~/GitHub/Fall2018-Project2-sec1_proj2_gr5/data")
housing<- read.csv("housing.csv",header=TRUE, stringsAsFactors =FALSE)
housing<- subset(housing, !is.na(lng))
housing
View(housing)
is.na(housing)
sum(is.na(housing))
bedroom_filter=housing$bedrooms>input$min_bedrooms
bathroom_filter=housing$bathrooms>input$min_bathrooms
housing$bathrooms
housing$price
observe({leafletProxy("map")%>%clearGroup("housing_cluster")
observe({leafletProxy("map")%>%clearGroup("housing_cluster")%>%
addMarkers(data=housingFilter(),
lng=~lng,
lat=~lat,
clusterOptions=markerClusterOptions(),
group="housing_cluster"
)
})
output$map <- renderLeaflet({
leaflet() %>%
addProviderTiles('Esri.WorldTopoMap') %>%
setView(lng = -73.971035, lat = 40.775659, zoom = 12) %>%
addMarkers(data=housing,
lng=~lng,
lat=~lat,
clusterOptions=markerClusterOptions(),
group="housing_cluster"
)
})
observe({leafletProxy("map")%>%clearGroup("housing_cluster")%>%
addMarkers(data=housingFilter(),
lng=~lng,
lat=~lat,
clusterOptions=markerClusterOptions(),
group="housing_cluster"
)
})
runApp('~/GitHub/Fall2018-Project2-sec1_proj2_gr5/app')
runApp('~/GitHub/Fall2018-Project2-sec1_proj2_gr5/app')
runApp('~/GitHub/Fall2018-Project2-sec1_proj2_gr5/app')
runApp('~/GitHub/Fall2018-Project2-sec1_proj2_gr5/app')
